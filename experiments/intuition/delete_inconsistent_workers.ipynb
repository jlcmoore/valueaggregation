{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13cbeaf6-308e-42f3-b3c7-adf9f99a137f",
   "metadata": {},
   "source": [
    "What follows is code to delete (move) all workers who have been inconsistent on a task from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12da0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import csv\n",
    "\n",
    "import value_aggregation as pm\n",
    "import model_experiment\n",
    "from shared_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8659b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIOS_DIR = 'data/scenarios'\n",
    "MTURK_RESULTS_DIR = \"data/results/mturk\"\n",
    "LLM_RESULTS_DIR = 'data/results/llm'\n",
    "\n",
    "scenario = \"maximize=True_num-agents=3_belief-steps=10_belief-range=[0.1,0.9]_action-steps=101_action-range=1,101_action-function-log=False_prevent-ties=True_agg-functions=['nash','fehr','util']_disagrees-only=False_num-scenarios=4_sample-size=68.0\"\n",
    "num_scenarios = 4\n",
    "scenario_file = os.path.join(SCENARIOS_DIR, scenario + \".csv\")\n",
    "\n",
    "\n",
    "run_dir = os.path.join(MTURK_RESULTS_DIR, scenario)\n",
    "\n",
    "\n",
    "fail_dir = os.path.join(run_dir, \"failed_checks\")\n",
    "# os.mkdir(fail_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ea7c7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chart_type=area_maximize=True.csv: 0/102 duplicate workers\n",
      "chart_type=area_maximize=True.csv: 0/0.00 failed checks out of 102\n",
      "chart_type=both_maximize=True.csv: 0/102 duplicate workers\n",
      "chart_type=both_maximize=True.csv: 0/0.00 failed checks out of 102\n",
      "chart_type=none_maximize=True.csv: 23/102 duplicate workers\n",
      "chart_type=none_maximize=True.csv: 48/0.47 failed checks out of 102\n",
      "chart_type=volume_maximize=True.csv: 0/102 duplicate workers\n",
      "chart_type=volume_maximize=True.csv: 0/0.00 failed checks out of 102\n"
     ]
    }
   ],
   "source": [
    "## This is the loop\n",
    "\n",
    "for condition in os.listdir(run_dir):\n",
    "    filename = os.path.join(run_dir, condition)    \n",
    "    if condition in [\".DS_Store\"] or \"duplicate\" in condition or os.path.isdir(filename):\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "    num_workers = len(df)\n",
    "\n",
    "    is_first = df['WorkerId'].duplicated(keep='first')\n",
    "\n",
    "    non_duplicates = df[~is_first]\n",
    "    duplicates = df[is_first]\n",
    "\n",
    "    print(f\"{condition}: {len(duplicates)}/{len(df)} duplicate workers\")\n",
    "\n",
    "    ex_df = mturk_explode_df(non_duplicates, num_scenarios)\n",
    "\n",
    "    mturk_df = (ex_df[ex_df['attention-answer'] == ex_df['attention-response']])\n",
    "\n",
    "    this_failed_checks = ex_df[ex_df['attention-answer'] != ex_df['attention-response']]\n",
    "\n",
    "    workers_failed = this_failed_checks['WorkerId'].unique()\n",
    "    workers_passed = mturk_df[~mturk_df['WorkerId'].isin(workers_failed)]\n",
    "\n",
    "    print(f\"{condition}: {len(workers_failed)}/{len(workers_failed) / num_workers:.2f} failed checks out of {num_workers}\")\n",
    "\n",
    "    failed = pd.concat([non_duplicates[non_duplicates['WorkerId'].isin(workers_failed)], duplicates])\n",
    "    not_failed = non_duplicates[~non_duplicates['WorkerId'].isin(workers_failed)]\n",
    "\n",
    "    temp_cols = ['Answer.q_question-{0}', 'Answer.q_question-{0}_attn', 'Answer.q_question-{0}_attn_answer']\n",
    "    cols = ['HITId', 'HITTypeId', 'Title', 'Description', 'Keywords', 'Reward',\n",
    "           'CreationTime', 'MaxAssignments', 'RequesterAnnotation',\n",
    "           'AssignmentDurationInSeconds', 'AutoApprovalDelayInSeconds',\n",
    "           'Expiration', 'AssignmentId', 'WorkerId', 'AssignmentStatus',\n",
    "           'AcceptTime', 'SubmitTime', 'AutoApprovalTime', 'ApprovalTime',\n",
    "           'RejectionTime', 'RequesterFeedback', 'Approve', 'Reject', 'IntegerId']\n",
    "    for col in temp_cols:\n",
    "        for i in range(1 , 4 + 1):\n",
    "            cols.append(col.format(i))\n",
    "\n",
    "    failed_cleared = failed.copy()\n",
    "    failed_cleared.loc[:, cols] = np.nan\n",
    "    not_failed_and_cleared = pd.concat([failed_cleared, not_failed])\n",
    "\n",
    "    fail_filename = os.path.join(fail_dir, condition)\n",
    "\n",
    "    failed.to_csv(fail_filename , index=False, quoting=csv.QUOTE_ALL)\n",
    "    not_failed_and_cleared.to_csv(filename, index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae1543dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a new file to submit to mturk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4ffac3-b960-4f08-a7ab-624621ef4078",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cruft below used to temporarily generate and check the results for the none trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94ab7820-d880-4d5a-aa4f-c3a278d06e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chart_type=none_maximize=True: 0/102 duplicate workers\n",
      "chart_type=none_maximize=True: 0/0.00 failed checks out of 102\n"
     ]
    }
   ],
   "source": [
    "## This is the loop\n",
    "\n",
    "condition = 'chart_type=none_maximize=True'\n",
    "filename = os.path.join(os.path.join(MTURK_RESULTS_DIR, scenario), f'{condition}.csv')\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "num_workers = len(df)\n",
    "\n",
    "is_first = df['WorkerId'].duplicated(keep='first')\n",
    "\n",
    "non_duplicates = df[~is_first]\n",
    "duplicates = df[is_first]\n",
    "\n",
    "print(f\"{condition}: {len(duplicates)}/{len(df)} duplicate workers\")\n",
    "\n",
    "ex_df = mturk_explode_df(non_duplicates, num_scenarios)\n",
    "\n",
    "mturk_df = (ex_df[ex_df['attention-answer'] == ex_df['attention-response']])\n",
    "\n",
    "this_failed_checks = ex_df[ex_df['attention-answer'] != ex_df['attention-response']]\n",
    "\n",
    "workers_failed = this_failed_checks['WorkerId'].unique()\n",
    "workers_passed = mturk_df[~mturk_df['WorkerId'].isin(workers_failed)]\n",
    "\n",
    "print(f\"{condition}: {len(workers_failed)}/{len(workers_failed) / num_workers:.2f} failed checks out of {num_workers}\")\n",
    "\n",
    "failed = pd.concat([non_duplicates[non_duplicates['WorkerId'].isin(workers_failed)], duplicates])\n",
    "not_failed = non_duplicates[~non_duplicates['WorkerId'].isin(workers_failed)]\n",
    "\n",
    "temp_cols = ['Answer.q_question-{0}', 'Answer.q_question-{0}_attn', 'Answer.q_question-{0}_attn_answer']\n",
    "cols = ['HITId', 'HITTypeId', 'Title', 'Description', 'Keywords', 'Reward',\n",
    "       'CreationTime', 'MaxAssignments', 'RequesterAnnotation',\n",
    "       'AssignmentDurationInSeconds', 'AutoApprovalDelayInSeconds',\n",
    "       'Expiration', 'AssignmentId', 'WorkerId', 'AssignmentStatus',\n",
    "       'AcceptTime', 'SubmitTime', 'AutoApprovalTime', 'ApprovalTime',\n",
    "       'RejectionTime', 'RequesterFeedback', 'Approve', 'Reject', 'IntegerId']\n",
    "for col in temp_cols:\n",
    "    for i in range(1 , 4 + 1):\n",
    "        cols.append(col.format(i))\n",
    "\n",
    "failed_cleared = failed.copy()\n",
    "failed_cleared.loc[:, cols] = np.nan\n",
    "not_failed_and_cleared = pd.concat([failed_cleared, not_failed])\n",
    "\n",
    "fail_filename = os.path.join(fail_dir, condition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68a0b42a-2224-4cc2-9ef9-44640ba56ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed.to_csv(fail_filename + \".csv\", index=False, quoting=csv.QUOTE_ALL)\n",
    "not_failed_and_cleared.to_csv(filename, index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5dc9a21f-9927-4ff7-9ca4-0727948dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data/results/mturk/maximize=True_num-agents=3_belief-steps=10_belief-range=[0.1,0.9]_action-steps=101_action-range=1,101_action-function-log=False_prevent-ties=True_agg-functions=['nash','fehr','util']_disagrees-only=False_num-scenarios=4_sample-size=68.0/chart_type=none_maximize=True.csv\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "daf9b20c-dc37-4b77-b2ed-37c9b469ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = 'chart_type=none_maximize=True'\n",
    "filename = os.path.join(os.path.join(MTURK_RESULTS_DIR, scenario), f'{condition}.csv')\n",
    "df = pd.read_csv(filename)\n",
    "d = df[df['HITId'].isnull()]\n",
    "columns = []\n",
    "delete = []\n",
    "for col in d.columns:\n",
    "    if 'Input' in col:\n",
    "        columns.append(col)\n",
    "    else:\n",
    "        delete.append(col)\n",
    "d = d.drop(delete, axis=1)\n",
    "renamed = {col : col[len('Input.'):] for col in columns}\n",
    "d = d.rename(columns=renamed)\n",
    "d.to_csv(os.path.join(SCENARIOS_DIR, f'{condition}_partial.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b586059-b255-4b5a-8d0b-6a2005f29e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-parliament",
   "language": "python",
   "name": "env-parliament"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
